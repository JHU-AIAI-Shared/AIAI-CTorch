{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script introduces the data format used in CTorch package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import python package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all the computation by CTorch involves two kinds of data: projection-domain data and image-domain data. Both of them are [PyTorch tensor](https://pytorch.org/docs/stable/tensors.html), and their shapes are consistent with those used in the PyTorch deep learning training (usually batch x channel x spatial dimensions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, 2D image-domain data has four dimensions: (batch_size, channel_size, height, width). batch_size is the number of images being parallelly processed. channel_size is the number of channels of the input image, it is 1 for most cases since the CT images are grayscale, but can represent the number of [basis materials or spectral channels in the spectral problem](https://pubs.rsna.org/doi/full/10.1148/rg.2016150220)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn([2, 3, 512, 512]) # (batch_size=2, channel_size=3, height=512, width=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D image-domain data adds an extra depth dimension: (batch_size, channel_size, depth, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn([2, 3, 256, 512, 512]) # (batch_size=2, channel_size=3, depth=256, height=512, width=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D projection-domain data has four dimensions: (batch_size, channel_size, num_views, num_pixels). batch_size and channel_size share the same definitions as those in the image-domain data. num_views and num_pixels represents the number of views/projection and number of 1D detector pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = torch.randn([2, 3, 720, 1024]) # (batch_size=2, channel_size=3, num_views=720, num_pixels=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D projetion-domain data add an extra projection dimension: (batch_size, channel_size, num_views, num_pixels_v, num_pixels_u). num_pixels_v and num_pixels_u represents the number of pixels of 2D detector on u(horizontal) and v(vertical) diections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = torch.randn([2, 3, 720, 384, 1024]) # (batch_size=2, channel_size=3, num_views=720, num_pixels_v=384, num_pixels_u=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Almost all the differentiable operators in CTorch only accept the data with the shape introduced above to make sure the input and output are compatiable with the PyTorch built-in operators. Even for a single slice grayscale image, make sure its shape is (1, 1, height, width)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "install",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
